{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "# import torch.optim as optim\n",
    "# from torch.optim import lr_scheduler\n",
    "# import numpy as np\n",
    "# import torchvision\n",
    "# from torchvision import models, transforms\n",
    "# import matplotlib\n",
    "# import matplotlib.pyplot as plt\n",
    "# import time\n",
    "# import os\n",
    "# import copy\n",
    "# import random\n",
    "# from datetime import datetime\n",
    "# from torch.utils.tensorboard import SummaryWriter\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# from data_helper import UnlabeledDataset, LabeledDataset\n",
    "# from helper import collate_fn, draw_box, compute_ts_road_map\n",
    "# from modelzoo import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/scratch/mz2476/DL/project/\")\n",
    "\n",
    "from modelzoo import encoder\n",
    "\n",
    "from ssl_project.ssl_ideas.model import ShuffleAndLearnModel\n",
    "from ssl_project.utils import to_np\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import pytorch_lightning as pl \n",
    "from argparse import Namespace\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from pl_modules import VariationalAutoEncoder, AutoEncoder, MMDVariationalAutoEncoder\n",
    "from argparse import Namespace\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "from ssl_project.paths import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "## Example\n",
    "###\n",
    "\n",
    "# new_model = ShuffleAndLearnModel.load_from_checkpoint(\n",
    "#     checkpoint_path=\"../ssl_ideas/lightning_logs/first_try_many_encoders=False/version_03/checkpoints/epoch=1.ckpt\")\n",
    "# encoder = new_model.model.resnet_encoder\n",
    "# torch.save(encoder, \"../pretrained_models/one_for_all_encoder_18.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'pl_modules' from '/scratch/mz2476/DL/project/ssl_project/vehicle_layout_prediction/pl_modules.py'>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "import pl_modules\n",
    "reload(pl_modules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment: vae_has_all_encoders_False_is_frozen_True_lr_encoder_multiplier_0.01\n",
      "Parameters...\n",
      "Namespace(batch_size=8, has_all_encoders=False, is_frozen=True, learning_rate=0.0001, lr_encoder_multiplier=0.01, n_scn_test=1, n_scn_train=24, n_scn_val=3, path_to_pretrained_model='/scratch/mz2476/DL/project/ssl_project/pretrained_models/one_for_all_encoder_18.pth', pretrained=False, resnet_style='18', threshold=0.5, weight_decay=1e-05)\n",
      "KEK\n"
     ]
    }
   ],
   "source": [
    "has_all_encoders = False\n",
    "\n",
    "if has_all_encoders:\n",
    "    path_to_pretrained_model = f\"{PATH_TO_REPO}/pretrained_models/cam_name_to_encoder.pth\"\n",
    "else:\n",
    "    path_to_pretrained_model = f\"{PATH_TO_REPO}/pretrained_models/one_for_all_encoder_18.pth\"\n",
    "    \n",
    "\n",
    "hparams =  Namespace(\n",
    "   **{\"resnet_style\": \"18\",\n",
    "      \"pretrained\": False,\n",
    "      \"has_all_encoders\": has_all_encoders,\n",
    "      \"path_to_pretrained_model\" : path_to_pretrained_model,\n",
    "      \"threshold\": 0.5,\n",
    "      \"n_scn_train\": 24,\n",
    "      \"n_scn_val\": 3, \n",
    "      \"n_scn_test\": 1,\n",
    "      \"batch_size\": 8,\n",
    "      \"learning_rate\": 0.0001,\n",
    "      \"weight_decay\": 0.00001,\n",
    "      \"is_frozen\": True,\n",
    "      \"lr_encoder_multiplier\" : 1e-2,\n",
    "     }\n",
    ")\n",
    "\n",
    "experiment_name = f\"vae_has_all_encoders_{hparams.has_all_encoders}_is_frozen_{hparams.is_frozen}_lr_encoder_multiplier_{hparams.lr_encoder_multiplier}\"\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "                    filepath=\"./checkpoints/\" + experiment_name + \"/checkpoint_{epoch}_{val_ts:.3f}\",\n",
    "                    save_top_k=3,\n",
    "                    verbose=False,\n",
    "                    monitor='val_ts',\n",
    "                    mode='max',\n",
    "                    prefix=''\n",
    "                )\n",
    "\n",
    "print(f\"Experiment: {experiment_name}\")\n",
    "print(\"Parameters...\")\n",
    "print(hparams)\n",
    "\n",
    "logger = pl.loggers.TensorBoardLogger(\"tb_logs\", experiment_name)\n",
    "logger.log_hyperparams(hparams)\n",
    "model = pl_modules.VariationalAutoEncoderPretrainedHead(hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.model.encoder.requires_grad_(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for name, param in model.named_parameters():\n",
    "#     print(f\"{name:60} {param.requires_grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightning:GPU available: True, used: False\n",
      "INFO:lightning:Set SLURM handle signals.\n",
      "INFO:lightning:\n",
      "   | Name                                          | Type                 | Params\n",
      "-----------------------------------------------------------------------------------\n",
      "0  | model                                         | vae                  | 48 M  \n",
      "1  | model.encoder                                 | encoder              | 11 M  \n",
      "2  | model.encoder.resnet_encoder                  | Sequential           | 11 M  \n",
      "3  | model.encoder.resnet_encoder.0                | Conv2d               | 9 K   \n",
      "4  | model.encoder.resnet_encoder.1                | BatchNorm2d          | 128   \n",
      "5  | model.encoder.resnet_encoder.2                | ReLU                 | 0     \n",
      "6  | model.encoder.resnet_encoder.3                | MaxPool2d            | 0     \n",
      "7  | model.encoder.resnet_encoder.4                | Sequential           | 147 K \n",
      "8  | model.encoder.resnet_encoder.4.0              | BasicBlock           | 73 K  \n",
      "9  | model.encoder.resnet_encoder.4.0.conv1        | Conv2d               | 36 K  \n",
      "10 | model.encoder.resnet_encoder.4.0.bn1          | BatchNorm2d          | 128   \n",
      "11 | model.encoder.resnet_encoder.4.0.relu         | ReLU                 | 0     \n",
      "12 | model.encoder.resnet_encoder.4.0.conv2        | Conv2d               | 36 K  \n",
      "13 | model.encoder.resnet_encoder.4.0.bn2          | BatchNorm2d          | 128   \n",
      "14 | model.encoder.resnet_encoder.4.1              | BasicBlock           | 73 K  \n",
      "15 | model.encoder.resnet_encoder.4.1.conv1        | Conv2d               | 36 K  \n",
      "16 | model.encoder.resnet_encoder.4.1.bn1          | BatchNorm2d          | 128   \n",
      "17 | model.encoder.resnet_encoder.4.1.relu         | ReLU                 | 0     \n",
      "18 | model.encoder.resnet_encoder.4.1.conv2        | Conv2d               | 36 K  \n",
      "19 | model.encoder.resnet_encoder.4.1.bn2          | BatchNorm2d          | 128   \n",
      "20 | model.encoder.resnet_encoder.5                | Sequential           | 525 K \n",
      "21 | model.encoder.resnet_encoder.5.0              | BasicBlock           | 230 K \n",
      "22 | model.encoder.resnet_encoder.5.0.conv1        | Conv2d               | 73 K  \n",
      "23 | model.encoder.resnet_encoder.5.0.bn1          | BatchNorm2d          | 256   \n",
      "24 | model.encoder.resnet_encoder.5.0.relu         | ReLU                 | 0     \n",
      "25 | model.encoder.resnet_encoder.5.0.conv2        | Conv2d               | 147 K \n",
      "26 | model.encoder.resnet_encoder.5.0.bn2          | BatchNorm2d          | 256   \n",
      "27 | model.encoder.resnet_encoder.5.0.downsample   | Sequential           | 8 K   \n",
      "28 | model.encoder.resnet_encoder.5.0.downsample.0 | Conv2d               | 8 K   \n",
      "29 | model.encoder.resnet_encoder.5.0.downsample.1 | BatchNorm2d          | 256   \n",
      "30 | model.encoder.resnet_encoder.5.1              | BasicBlock           | 295 K \n",
      "31 | model.encoder.resnet_encoder.5.1.conv1        | Conv2d               | 147 K \n",
      "32 | model.encoder.resnet_encoder.5.1.bn1          | BatchNorm2d          | 256   \n",
      "33 | model.encoder.resnet_encoder.5.1.relu         | ReLU                 | 0     \n",
      "34 | model.encoder.resnet_encoder.5.1.conv2        | Conv2d               | 147 K \n",
      "35 | model.encoder.resnet_encoder.5.1.bn2          | BatchNorm2d          | 256   \n",
      "36 | model.encoder.resnet_encoder.6                | Sequential           | 2 M   \n",
      "37 | model.encoder.resnet_encoder.6.0              | BasicBlock           | 919 K \n",
      "38 | model.encoder.resnet_encoder.6.0.conv1        | Conv2d               | 294 K \n",
      "39 | model.encoder.resnet_encoder.6.0.bn1          | BatchNorm2d          | 512   \n",
      "40 | model.encoder.resnet_encoder.6.0.relu         | ReLU                 | 0     \n",
      "41 | model.encoder.resnet_encoder.6.0.conv2        | Conv2d               | 589 K \n",
      "42 | model.encoder.resnet_encoder.6.0.bn2          | BatchNorm2d          | 512   \n",
      "43 | model.encoder.resnet_encoder.6.0.downsample   | Sequential           | 33 K  \n",
      "44 | model.encoder.resnet_encoder.6.0.downsample.0 | Conv2d               | 32 K  \n",
      "45 | model.encoder.resnet_encoder.6.0.downsample.1 | BatchNorm2d          | 512   \n",
      "46 | model.encoder.resnet_encoder.6.1              | BasicBlock           | 1 M   \n",
      "47 | model.encoder.resnet_encoder.6.1.conv1        | Conv2d               | 589 K \n",
      "48 | model.encoder.resnet_encoder.6.1.bn1          | BatchNorm2d          | 512   \n",
      "49 | model.encoder.resnet_encoder.6.1.relu         | ReLU                 | 0     \n",
      "50 | model.encoder.resnet_encoder.6.1.conv2        | Conv2d               | 589 K \n",
      "51 | model.encoder.resnet_encoder.6.1.bn2          | BatchNorm2d          | 512   \n",
      "52 | model.encoder.resnet_encoder.7                | Sequential           | 8 M   \n",
      "53 | model.encoder.resnet_encoder.7.0              | BasicBlock           | 3 M   \n",
      "54 | model.encoder.resnet_encoder.7.0.conv1        | Conv2d               | 1 M   \n",
      "55 | model.encoder.resnet_encoder.7.0.bn1          | BatchNorm2d          | 1 K   \n",
      "56 | model.encoder.resnet_encoder.7.0.relu         | ReLU                 | 0     \n",
      "57 | model.encoder.resnet_encoder.7.0.conv2        | Conv2d               | 2 M   \n",
      "58 | model.encoder.resnet_encoder.7.0.bn2          | BatchNorm2d          | 1 K   \n",
      "59 | model.encoder.resnet_encoder.7.0.downsample   | Sequential           | 132 K \n",
      "60 | model.encoder.resnet_encoder.7.0.downsample.0 | Conv2d               | 131 K \n",
      "61 | model.encoder.resnet_encoder.7.0.downsample.1 | BatchNorm2d          | 1 K   \n",
      "62 | model.encoder.resnet_encoder.7.1              | BasicBlock           | 4 M   \n",
      "63 | model.encoder.resnet_encoder.7.1.conv1        | Conv2d               | 2 M   \n",
      "64 | model.encoder.resnet_encoder.7.1.bn1          | BatchNorm2d          | 1 K   \n",
      "65 | model.encoder.resnet_encoder.7.1.relu         | ReLU                 | 0     \n",
      "66 | model.encoder.resnet_encoder.7.1.conv2        | Conv2d               | 2 M   \n",
      "67 | model.encoder.resnet_encoder.7.1.bn2          | BatchNorm2d          | 1 K   \n",
      "68 | model.encoder.resnet_encoder.8                | AdaptiveAvgPool2d    | 0     \n",
      "69 | model.encoder_after_resnet                    | encoder_after_resnet | 33 M  \n",
      "70 | model.encoder_after_resnet.conv               | Sequential           | 33 M  \n",
      "71 | model.encoder_after_resnet.conv.0             | Conv2d               | 28 M  \n",
      "72 | model.encoder_after_resnet.conv.1             | BatchNorm2d          | 2 K   \n",
      "73 | model.encoder_after_resnet.conv.2             | ReLU                 | 0     \n",
      "74 | model.encoder_after_resnet.conv.3             | Conv2d               | 4 M   \n",
      "75 | model.encoder_after_resnet.conv.4             | BatchNorm2d          | 1 K   \n",
      "76 | model.encoder_after_resnet.conv.5             | ReLU                 | 0     \n",
      "77 | model.encoder_after_resnet.conv.6             | MaxPool2d            | 0     \n",
      "78 | model.vae_decoder                             | vae_decoder          | 3 M   \n",
      "79 | model.vae_decoder.deconv_decoder              | Sequential           | 3 M   \n",
      "80 | model.vae_decoder.deconv_decoder.0            | ConvTranspose2d      | 1 M   \n",
      "81 | model.vae_decoder.deconv_decoder.1            | BatchNorm2d          | 2 K   \n",
      "82 | model.vae_decoder.deconv_decoder.2            | ReLU                 | 0     \n",
      "83 | model.vae_decoder.deconv_decoder.3            | ConvTranspose2d      | 2 M   \n",
      "84 | model.vae_decoder.deconv_decoder.4            | BatchNorm2d          | 1 K   \n",
      "85 | model.vae_decoder.deconv_decoder.5            | ReLU                 | 0     \n",
      "86 | model.vae_decoder.deconv_decoder.6            | ConvTranspose2d      | 524 K \n",
      "87 | model.vae_decoder.deconv_decoder.7            | BatchNorm2d          | 512   \n",
      "88 | model.vae_decoder.deconv_decoder.8            | ReLU                 | 0     \n",
      "89 | model.vae_decoder.deconv_decoder.9            | ConvTranspose2d      | 131 K \n",
      "90 | model.vae_decoder.deconv_decoder.10           | BatchNorm2d          | 256   \n",
      "91 | model.vae_decoder.deconv_decoder.11           | ReLU                 | 0     \n",
      "92 | model.vae_decoder.deconv_decoder.12           | ConvTranspose2d      | 32 K  \n",
      "93 | model.vae_decoder.deconv_decoder.13           | BatchNorm2d          | 128   \n",
      "94 | model.vae_decoder.deconv_decoder.14           | ReLU                 | 0     \n",
      "95 | model.vae_decoder.deconv_decoder.15           | ConvTranspose2d      | 256   \n",
      "96 | model.vae_decoder.deconv_decoder.16           | Sigmoid              | 0     \n",
      "97 | BCE                                           | BCELoss              | 0     \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72504cb357744c569d3b919423e4da83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layoutâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x2aec1bbb4040>\n",
      "Traceback (most recent call last):\n",
      "  File \"/scratch/mz2476/miniconda3/envs/pDL/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/scratch/mz2476/miniconda3/envs/pDL/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/scratch/mz2476/miniconda3/envs/pDL/lib/python3.8/multiprocessing/process.py\", line 147, in join\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x2aec1bbb4040>\n",
      "Traceback (most recent call last):\n",
      "  File \"/scratch/mz2476/miniconda3/envs/pDL/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 961, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/scratch/mz2476/miniconda3/envs/pDL/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 941, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/scratch/mz2476/miniconda3/envs/pDL/lib/python3.8/multiprocessing/process.py\", line 147, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "AssertionError: can only join a child process\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(logger=logger, gpus=0, max_epochs=50, val_check_interval=0.2,\n",
    "                     checkpoint_callback=checkpoint_callback)\n",
    "\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segm to bb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from ssl_project.utils import compute_ats_bounding_boxes, get_bounding_boxes_from_seg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmentation = np.zeros((800, 800))\n",
    "\n",
    "segmentation[300:330, 90:160] = 1\n",
    "segmentation[290:320, 190:260] = 1\n",
    "\n",
    "pred_map = torch.Tensor(segmentation)\n",
    "threshold = 0.5\n",
    "\n",
    "bb_pred = get_bounding_boxes_from_seg(pred_map > threshold, 10, 800, 800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-30e4a53fdeac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msegmentation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "plt.imshow(segmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-11-27c3d2489c7c>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-11-27c3d2489c7c>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    ts_road_map = compute_ats_bounding_boxes(bb_pred.cpu(), target[\"bounding_box\"].cpu())\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "bb_pred = get_bounding_boxes_from_seg(pred_map > self.threshold, 10, 800, 800)\n",
    "            ts_road_map = compute_ats_bounding_boxes(bb_pred.cpu(), target[\"bounding_box\"].cpu())\n",
    "            threat_score += ts_road_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
